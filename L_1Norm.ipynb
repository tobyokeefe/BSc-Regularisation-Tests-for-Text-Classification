{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "0      dear american teens question dutch person hear...      0\n",
      "1      nothing look forward lifei dont many reasons k...      1\n",
      "2      music recommendations im looking expand playli...      0\n",
      "3      im done trying feel betterthe reason im still ...      1\n",
      "4      worried  year old girl subject domestic physic...      1\n",
      "...                                                  ...    ...\n",
      "27972  posting everyday people stop caring  religion ...      0\n",
      "27973  okay definetly need hear guys opinion ive pret...      0\n",
      "27974  cant get dog think ill kill myselfthe last thi...      1\n",
      "27975  whats point princess bridei really think like ...      1\n",
      "27976  got nudes person might might know snapchat do ...      0\n",
      "\n",
      "[27977 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "path_name = 'your_path_name_here/mental_health.csv'\n",
    "df=pd.read_csv(path_name)\n",
    "print(df)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#Split the matrix into predictors and response \n",
    "msg=df[\"text\"]\n",
    "msg=msg.str.replace('[^a-zA-Z0-9]+',\" h\", regex = True) \n",
    "y=df['label'].values\n",
    "y \n",
    "\n",
    "\n",
    "#Stemming and Tokenising\n",
    "stemmer=PorterStemmer()\n",
    "msg=msg.apply(lambda line:[stemmer.stem(token.lower()) for token in word_tokenize(line)]).apply(lambda token:\" \".join(token))\n",
    "msg=msg.apply(lambda line:[token for token in word_tokenize(line) if len(token)>2]).apply(lambda y:\" \".join(y))\n",
    "\n",
    "#Vectorising\n",
    "tf=TfidfVectorizer() \n",
    "data_vec=tf.fit_transform(msg)\n",
    "\n",
    "#Train, Validation, and Test Split ###RANDOMSTATE=1###\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.3 implies 70% will be used to training and 30% for testing. \n",
    "#random_state sets seed for random number generator, ensuring reducibility\n",
    "x_train,x_test,y_train,y_test=train_test_split(data_vec,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value selected by cross-validation: 2.5118864315096747\n",
      "Best lambda value (regularisation value) selected by cross-validation: 0.39810717055348227\n",
      "[0 1 1 ... 0 1 0]\n",
      "Accuracy on the test set: 0.9170638703527169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      4271\n",
      "           1       0.93      0.90      0.91      4121\n",
      "\n",
      "    accuracy                           0.92      8392\n",
      "   macro avg       0.92      0.92      0.92      8392\n",
      "weighted avg       0.92      0.92      0.92      8392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Lasso with 5 fold Cross Validation for Hyperparameter Tuning\n",
    "\n",
    "alphas = 10.0 ** np.arange(-5, 5, 0.1)\n",
    "\n",
    "cv_scores = [] \n",
    "\n",
    "# Perform cross-validation for each value of C\n",
    "for alpha in alphas:\n",
    "    modelLR_lasso = LogisticRegression(penalty='l1', C = 1/alpha, random_state=1, solver='liblinear')\n",
    "    scores = cross_val_score(modelLR_lasso, x_train, y_train, cv = 5)  # 5-fold cross-validation\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "\n",
    "# Find the index corresponding to the best C value\n",
    "best_CV_index = np.argmax(cv_scores)\n",
    "best_alpha = alphas[best_CV_index]\n",
    "\n",
    "# Inspect the best C value\n",
    "print(\"Best C value selected by cross-validation:\", 1/best_alpha)\n",
    "print(\"Best lambda value (regularisation value) selected by cross-validation:\", best_alpha)\n",
    "\n",
    "modelLR_lasso = LogisticRegression(penalty='l1', C=1/best_alpha, random_state=1, solver = 'liblinear')\n",
    "\n",
    "modelLR_lasso.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# Make predictions on a new set of data\n",
    "predictions = modelLR_lasso.predict(x_test)\n",
    "\n",
    "# Compare the predicted labels to the true labels\n",
    "accuracy_on_test_set = modelLR_lasso.score(x_test, y_test) #accuaracy = # of correct predictions / total # of predictions\n",
    "\n",
    "print(\"Accuracy on the test set:\", accuracy_on_test_set)\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
